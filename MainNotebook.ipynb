{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pymorphy2\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from collections import Counter\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from gensim.models.wrappers.fasttext import FastTextKeyedVectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse(word='собака', tag=OpencorporaTag('NOUN,anim,femn sing,nomn'), normal_form='собака', score=1.0, methods_stack=((<DictionaryAnalyzer>, 'собака', 403, 0),))\n"
     ]
    }
   ],
   "source": [
    "for i in morph.parse('собака'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "data = pd.read_csv('new_apps_compatible.csv', sep=';').drop('Пустая колонка для совместимости', axis=1)\n",
    "\n",
    "\n",
    "#Параллельно выполняющийся map функции func по массиву massive\n",
    "def parallelization(func,massive, tq=True):\n",
    "    \n",
    "    num_cores = multiprocessing.cpu_count() # Число наших ядер\n",
    "    if tq:\n",
    "        results = np.array(Parallel(n_jobs=num_cores)(delayed(func)(i) for i in tqdm(massive)))\n",
    "        return results\n",
    "    else:\n",
    "        results = Parallel(n_jobs=num_cores)(delayed(func)(i) for i in massive)\n",
    "        return results\n",
    "\n",
    "def _word2canonical4w2v(word):\n",
    "    elems = morph.parse(word)\n",
    "    my_tag = ''\n",
    "    res = []\n",
    "    for elem in elems:\n",
    "        if 'VERB' in elem.tag or 'GRND' in elem.tag or 'INFN' in elem.tag:\n",
    "            my_tag = 'V'\n",
    "        if 'NOUN' in elem.tag:\n",
    "            my_tag = 'S'\n",
    "        normalised = elem.normalized.word\n",
    "        res.append((normalised, my_tag))\n",
    "    tmp = list(filter(lambda x: x[1] != '', res))\n",
    "    if len(tmp) > 0:\n",
    "        return tmp[0]\n",
    "    else:\n",
    "        return res[0]\n",
    "\n",
    "    \n",
    "def word2canonical(word):\n",
    "    return _word2canonical4w2v(word)[0]\n",
    "\n",
    "\n",
    "def getWords(text, filter_short_words=False):\n",
    "    if filter_short_words:\n",
    "        return filter(lambda x: len(x) > 3, re.findall(r'(?u)\\w+', text))\n",
    "    else:\n",
    "        return re.findall(r'(?u)\\w+', text)\n",
    "\n",
    "\n",
    "def text2canonicals(text, add_word=False, filter_short_words=True):\n",
    "    words = []\n",
    "    for word in getWords(text, filter_short_words=filter_short_words):\n",
    "        words.append(word2canonical(word.lower()))\n",
    "        if add_word:\n",
    "            words.append(word.lower())\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1720/1720 [00:32<00:00, 52.60it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = parallelization(text2canonicals, data.Description.values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-король', 0.9802986979484558),\n",
       " ('королева', 0.9768819808959961),\n",
       " ('короля', 0.9556112289428711),\n",
       " ('короли', 0.9534466862678528),\n",
       " ('королевства', 0.9524538516998291),\n",
       " ('герцогиня', 0.9472317695617676),\n",
       " ('королю', 0.9463006854057312),\n",
       " ('королевич', 0.9376259446144104),\n",
       " ('королевстве', 0.9376195669174194),\n",
       " ('королевишна', 0.9349520206451416)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext.most_similar_cosmul(['женщина', 'король'], '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model_path = '/Users/egor/Downloads/187/model.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(object):\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(object):\n",
    "    def __init__(self, embeddings_path=None):\n",
    "        self.loss = None\n",
    "        self.model = None\n",
    "        \n",
    "    def get_embeddings(self):\n",
    "        assert self.embeddings_path is not None, 'you must specify embeddings path'\n",
    "        fasttext = FastTextKeyedVectors.load(self.embeddings_path)\n",
    "    \n",
    "    def get_loss(self):\n",
    "        # Implement pairwise loss\n",
    "        pass\n",
    "    \n",
    "    def get_prob(self, s1, s2):\n",
    "        return 1 / (1 + tf.exp(s1 - s2))\n",
    "    \n",
    "    def build(self):\n",
    "        # build arch of siamese network\n",
    "        pass\n",
    "    \n",
    "    def train(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
